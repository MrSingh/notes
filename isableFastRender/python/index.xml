<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pythons on Pauls&#39;s Notes On Data &amp; Software Engineering</title>
    <link>http://localhost:1313/python/</link>
    <description>Recent content in Pythons on Pauls&#39;s Notes On Data &amp; Software Engineering</description>
    <generator>Hugo</generator>
    <language>en-gb</language>
    <lastBuildDate>Wed, 20 Nov 2024 13:10:42 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Exploratory Data Analysis of CO2 Emissions Data with Python</title>
      <link>http://localhost:1313/python/co2_emissions_eda/</link>
      <pubDate>Mon, 18 Nov 2024 07:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/co2_emissions_eda/</guid>
      <description>EDGAR CO2 emissions data&#xA;This EDA is a work in progress and is the groundwork for a visulisation in Power Bi.&#xA;ToDo: Remove Global Total Row From the Top 20 and 5 Datasets % Increase in Avaiation and Shipping Extract Figures for Aviation and Shipping % of Total Emissions by the Top 20 - 1970 % of Total Emissions by the Top 5 - 1970 % of Total Emissions by the Top 20 - 2023 % of Total Emissions by the Top 5 - 2023 Total CO2 Emissions for Each Year Grand Total Emissions of Co2 Create a ToC Create A Visual/Dashboard An EDA of CO2 emissons based on EDGAR(Emissions Database for Global Atmospheric Research) data.</description>
    </item>
    <item>
      <title>CO2 Emmisions Analysis</title>
      <link>http://localhost:1313/python/co2_emmisions_analysis/</link>
      <pubDate>Sun, 17 Nov 2024 07:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/co2_emmisions_analysis/</guid>
      <description>Data Resource An analysis of CO2 emmisons based on Glaobal 2023 data.&#xA;# Import import pandas as pd import matplotlib.pyplot as plt import seaborn as sns # Load the dataset data = pd.read_csv(&amp;#39;data/world-data-2023.csv&amp;#39;) # Display The column names and data types print(data.dtypes) Country object&#xD;Density\n(P/Km2) object&#xD;Abbreviation object&#xD;Agricultural Land( %) object&#xD;Land Area(Km2) object&#xD;Armed Forces size object&#xD;Birth Rate float64&#xD;Calling Code float64&#xD;Capital/Major City object&#xD;Co2-Emissions object&#xD;CPI object&#xD;CPI Change (%) object&#xD;Currency-Code object&#xD;Fertility Rate float64&#xD;Forested Area (%) object&#xD;Gasoline Price object&#xD;GDP object&#xD;Gross primary education enrollment (%) object&#xD;Gross tertiary education enrollment (%) object&#xD;Infant mortality float64&#xD;Largest city object&#xD;Life expectancy float64&#xD;Maternal mortality ratio float64&#xD;Minimum wage object&#xD;Official language object&#xD;Out of pocket health expenditure object&#xD;Physicians per thousand float64&#xD;Population object&#xD;Population: Labor force participation (%) object&#xD;Tax revenue (%) object&#xD;Total tax rate object&#xD;Unemployment rate object&#xD;Urban_population object&#xD;Latitude float64&#xD;Longitude float64&#xD;dtype: object&#xD;# Convert &amp;#39;Co2-Emissions&amp;#39; to numeric data[&amp;#39;Co2-Emissions&amp;#39;] = pd.</description>
    </item>
    <item>
      <title>Flatten a Multi-Index DataFrame</title>
      <link>http://localhost:1313/python/flatten_multiindex_dataframe/</link>
      <pubDate>Fri, 15 Nov 2024 07:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/flatten_multiindex_dataframe/</guid>
      <description>Resource Whilst a multi-index datafame can be useful for complex data orginisation, for example across multiple markets and time periods. Flattening the data has it&amp;rsquo;s own advantages; making for easier data manipulation, merging with other datasets and visulising. Here is a quick example.&#xA;# Import import pandas as pd import yfinance as yf # Fetch data #S&amp;amp;P 500 Vanguard - VOO #S&amp;amp;P 500 Black Rock - BSPIX tickers = [&amp;#39;VOO&amp;#39;,&amp;#39;VTWO&amp;#39;] df = yf.</description>
    </item>
    <item>
      <title>Normalising ETF Adjusted Close Prices in a Multi-Index DataFrame</title>
      <link>http://localhost:1313/python/normalise_multiindex_data/</link>
      <pubDate>Thu, 14 Nov 2024 07:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/normalise_multiindex_data/</guid>
      <description>This example fetches historical price data for two ETFs, &amp;lsquo;VOO&amp;rsquo; and &amp;lsquo;VTWO&amp;rsquo;, using the yfinance library and storing it in a Multi-Index DataFrame. It then iterates through each ticker symbol to normalise their adjusted closing prices based on the first day&amp;rsquo;s value. The normalised prices are stored in new columns in the DataFrame.&#xA;Normalising data is important for a number of reasons:&#xA;Comparison Across Assets Trend Analysis Volatility Assessment Portfolio Management Visualization See my short guide to normalising data here</description>
    </item>
    <item>
      <title>Primitive Data Types</title>
      <link>http://localhost:1313/python/primitive_data_types/</link>
      <pubDate>Fri, 19 Feb 2021 07:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/primitive_data_types/</guid>
      <description>Resource&#xA;Python has a number of built-in data types but for the purpose of this notebook, we will focus on what are referred to as primitive data types. The primitive data types are as follows.&#xA;Integer - Whole numbers Float - Deciaml numbers String - Character data Boolean - True or False None - None Object or NoneType Integers Whole Numbers # Positive Integer num = 10 # Check data type type(num) int&#xD;# Negative Integer negative_num = -10 # Check data type type(num) int&#xD;#Zero zero = 0 # Check data type type(zero) int&#xD;Floats # Floating or Decimal Number decimal_num = 2.</description>
    </item>
    <item>
      <title>Creating Arrays with NumPy</title>
      <link>http://localhost:1313/python/creating_arrays/</link>
      <pubDate>Thu, 11 Feb 2021 06:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/creating_arrays/</guid>
      <description>Resources NumPy NumPy API # Import NumPy import numpy as np # Create a list list_1 = [1,2,3,4,5] # Create another list # we will use this later list_2 = [6,7,8,9,10] Create an Array with a List # Create a array by passing the list as an object new_array = np.array(list_1) new_array Create a multi-dimensional array or matrix # Create a list of lists list_of_lists = [list_1, list_2] list_of_lists # Create a multi-dimensional array or matrix matrix_array = np.</description>
    </item>
    <item>
      <title>New Format Basics</title>
      <link>http://localhost:1313/python/format_basics/</link>
      <pubDate>Mon, 08 Feb 2021 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/format_basics/</guid>
      <description>Resource&#xA;Basic Example # Name input name = input() &amp;#39;Hello, {}&amp;#39;.format(name) &#39;Hello, SpiderMan&#39;&#xD;Dictionary Example data = {&amp;#39;first&amp;#39;: &amp;#39;Spider&amp;#39;, &amp;#39;last&amp;#39;: &amp;#39;-Man&amp;#39;} &amp;#39;{first}{last}&amp;#39;.format(**data) &#39;Spider-Man&#39;&#xD;List Example data = [&amp;#39;Spider&amp;#39;, &amp;#39;Man&amp;#39;] &amp;#39;{}-{}&amp;#39;.format(*data) &#39;Spider-Man&#39;&#xD;Class/Object Example class Person(object): type = &amp;#39;Enemies&amp;#39; names = [{&amp;#39;name&amp;#39;: &amp;#39;Doctor Octopus&amp;#39;}, {&amp;#39;name&amp;#39;: &amp;#39;Green Goblin&amp;#39;}] &amp;#39;{p.type}: {p.names[0][name]} and {p.names[1][name]}&amp;#39;.format(p=Person()) &#39;Enemies: Doctor Octopus and Green Goblin&#39;&#xD;Datetime Example from datetime import date &amp;#39;{:%Y-%m-%d}&amp;#39;.format(date.today()) &#39;2021-02-08&#39;&#xD;</description>
    </item>
    <item>
      <title>While Loops Basics</title>
      <link>http://localhost:1313/python/while_loop_basics/</link>
      <pubDate>Fri, 05 Feb 2021 12:44:38 +0000</pubDate>
      <guid>http://localhost:1313/python/while_loop_basics/</guid>
      <description>Simple While Loop # while loops until a condition is met - when x = 10 the condition is no longer met and the while loop stops # Inistalise counter i = 0 while i &amp;lt; 10: print(i) i += 1 0&#xD;1&#xD;2&#xD;3&#xD;4&#xD;5&#xD;6&#xD;7&#xD;8&#xD;9&#xD;While Loop To Sum i = 0 sum = 0 while i &amp;lt; 10: sum = sum + i i += 1 # update counter print(&amp;#34;Inside Loop | Sum = &amp;#34;, sum) print(&amp;#34;Outside | Loop Sum = &amp;#34;, sum) Inside Loop | Sum = 0&#xD;Inside Loop | Sum = 1&#xD;Inside Loop | Sum = 3&#xD;Inside Loop | Sum = 6&#xD;Inside Loop | Sum = 10&#xD;Inside Loop | Sum = 15&#xD;Inside Loop | Sum = 21&#xD;Inside Loop | Sum = 28&#xD;Inside Loop | Sum = 36&#xD;Inside Loop | Sum = 45&#xD;Outside | Loop Sum = 45&#xD;While loop with condition and nested if statement # while loops until a condition is met - along with a nested if condition therefore if x is less than 10 and x is less than 5 ends the loop x = 0 while x &amp;lt; 10: if x == 5: break print(x) x += 1 0&#xD;1&#xD;2&#xD;3&#xD;4&#xD;Infinite Loop example - Commeneted out!</description>
    </item>
    <item>
      <title>For Loops Basics</title>
      <link>http://localhost:1313/python/for_loop_basics/</link>
      <pubDate>Fri, 05 Feb 2021 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/for_loop_basics/</guid>
      <description>Create a List of Numbers nums = [1,2,3,4,5] Print Numbers in a List Example for num in nums: print(num) 1&#xD;2&#xD;3&#xD;4&#xD;5&#xD;Continue Example #continue moves to the next iteration - in the example below when num == 4, &amp;#39;Found!&amp;#39; will be printed and it will skip print(num) and go to the next iteration of the loop for num in nums: if num == 4: print(&amp;#39;Found!&amp;#39;) continue print(num) 1&#xD;2&#xD;3&#xD;Found!</description>
    </item>
    <item>
      <title>Delete Columns in a DataFrame</title>
      <link>http://localhost:1313/python/drop_dataframe_columns/</link>
      <pubDate>Thu, 04 Feb 2021 12:44:38 +0000</pubDate>
      <guid>http://localhost:1313/python/drop_dataframe_columns/</guid>
      <description>Resource Data Source Import Pandas # Import Pandas import pandas as pd Set File Path and Read it into a DataFrame # Set file path fp = &amp;#34;data/cereal.csv&amp;#34; # Read file to DataFrame df = pd.read_csv(fp, delimiter=&amp;#39;,&amp;#39;) Example One # Example One # Delete All Columns Except Named Columns df_1 = df[[&amp;#39;name&amp;#39;, &amp;#39;rating&amp;#39;]] df_1 name&#xD;rating&#xD;0&#xD;100% Bran&#xD;68.402973&#xD;1&#xD;100% Natural Bran&#xD;33.983679&#xD;2&#xD;All-Bran&#xD;59.425505&#xD;3&#xD;All-Bran with Extra Fiber&#xD;93.</description>
    </item>
    <item>
      <title>Write a Dataframe to a JSON File</title>
      <link>http://localhost:1313/python/write_dataframe_to_json/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 -0700</pubDate>
      <guid>http://localhost:1313/python/write_dataframe_to_json/</guid>
      <description>Resource Data Source Import Pandas # Import Pandas import pandas as pd df = pd.read_csv(&amp;#34;data/cereal.csv&amp;#34;) Output as a JSON string # output as a JSON string df.to_json() &#39;{&amp;quot;name&amp;quot;:{&amp;quot;0&amp;quot;:&amp;quot;100% Bran&amp;quot;,&amp;quot;1&amp;quot;:&amp;quot;100% Natural Bran&amp;quot;,&amp;quot;2&amp;quot;:&amp;quot;All-Bran&amp;quot;,&amp;quot;3&amp;quot;:&amp;quot;All-Bran with Extra Fiber&amp;quot;,&amp;quot;4&amp;quot;:&amp;quot;Almond Delight&amp;quot;,&amp;quot;5&amp;quot;:&amp;quot;Apple Cinnamon Cheerios&amp;quot;,&amp;quot;6&amp;quot;:&amp;quot;Apple Jacks&amp;quot;,&amp;quot;7&amp;quot;:&amp;quot;Basic 4&amp;quot;,&amp;quot;8&amp;quot;:&amp;quot;Bran Chex&amp;quot;,&amp;quot;9&amp;quot;:&amp;quot;Bran Flakes&amp;quot;,&amp;quot;10&amp;quot;:&amp;quot;Cap\&#39;n\&#39;Crunch&amp;quot;,&amp;quot;11&amp;quot;:&amp;quot;Cheerios&amp;quot;,&amp;quot;12&amp;quot;:&amp;quot;Cinnamon Toast Crunch&amp;quot;,&amp;quot;13&amp;quot;:&amp;quot;Clusters&amp;quot;,&amp;quot;14&amp;quot;:&amp;quot;Cocoa Puffs&amp;quot;,&amp;quot;15&amp;quot;:&amp;quot;Corn Chex&amp;quot;,&amp;quot;16&amp;quot;:&amp;quot;Corn Flakes&amp;quot;,&amp;quot;17&amp;quot;:&amp;quot;Corn Pops&amp;quot;,&amp;quot;18&amp;quot;:&amp;quot;Count Chocula&amp;quot;,&amp;quot;19&amp;quot;:&amp;quot;Cracklin\&#39; Oat Bran&amp;quot;,&amp;quot;20&amp;quot;:&amp;quot;Cream of Wheat (Quick)&amp;quot;,&amp;quot;21&amp;quot;:&amp;quot;Crispix&amp;quot;,&amp;quot;22&amp;quot;:&amp;quot;Crispy Wheat &amp;amp; Raisins&amp;quot;,&amp;quot;23&amp;quot;:&amp;quot;Double Chex&amp;quot;,&amp;quot;24&amp;quot;:&amp;quot;Froot Loops&amp;quot;,&amp;quot;25&amp;quot;:&amp;quot;Frosted Flakes&amp;quot;,&amp;quot;26&amp;quot;:&amp;quot;Frosted Mini-Wheats&amp;quot;,&amp;quot;27&amp;quot;:&amp;quot;Fruit &amp;amp; Fibre Dates; Walnuts; and Oats&amp;quot;,&amp;quot;28&amp;quot;:&amp;quot;Fruitful Bran&amp;quot;,&amp;quot;29&amp;quot;:&amp;quot;Fruity Pebbles&amp;quot;,&amp;quot;30&amp;quot;:&amp;quot;Golden Crisp&amp;quot;,&amp;quot;31&amp;quot;:&amp;quot;Golden Grahams&amp;quot;,&amp;quot;32&amp;quot;:&amp;quot;Grape Nuts Flakes&amp;quot;,&amp;quot;33&amp;quot;:&amp;quot;Grape-Nuts&amp;quot;,&amp;quot;34&amp;quot;:&amp;quot;Great Grains Pecan&amp;quot;,&amp;quot;35&amp;quot;:&amp;quot;Honey Graham Ohs&amp;quot;,&amp;quot;36&amp;quot;:&amp;quot;Honey Nut Cheerios&amp;quot;,&amp;quot;37&amp;quot;:&amp;quot;Honey-comb&amp;quot;,&amp;quot;38&amp;quot;:&amp;quot;Just Right Crunchy Nuggets&amp;quot;,&amp;quot;39&amp;quot;:&amp;quot;Just Right Fruit &amp;amp; Nut&amp;quot;,&amp;quot;40&amp;quot;:&amp;quot;Kix&amp;quot;,&amp;quot;41&amp;quot;:&amp;quot;Life&amp;quot;,&amp;quot;42&amp;quot;:&amp;quot;Lucky Charms&amp;quot;,&amp;quot;43&amp;quot;:&amp;quot;Maypo&amp;quot;,&amp;quot;44&amp;quot;:&amp;quot;Muesli Raisins; Dates; &amp;amp; Almonds&amp;quot;,&amp;quot;45&amp;quot;:&amp;quot;Muesli Raisins; Peaches; &amp;amp; Pecans&amp;quot;,&amp;quot;46&amp;quot;:&amp;quot;Mueslix Crispy Blend&amp;quot;,&amp;quot;47&amp;quot;:&amp;quot;Multi-Grain Cheerios&amp;quot;,&amp;quot;48&amp;quot;:&amp;quot;Nut&amp;amp;Honey Crunch&amp;quot;,&amp;quot;49&amp;quot;:&amp;quot;Nutri-Grain Almond-Raisin&amp;quot;,&amp;quot;50&amp;quot;:&amp;quot;Nutri-grain Wheat&amp;quot;,&amp;quot;51&amp;quot;:&amp;quot;Oatmeal Raisin Crisp&amp;quot;,&amp;quot;52&amp;quot;:&amp;quot;Post Nat.</description>
    </item>
    <item>
      <title>Requests and Beautiful Soup</title>
      <link>http://localhost:1313/python/ws_requests_and_beautifulsoup/</link>
      <pubDate>Fri, 29 Jan 2021 14:50:18 +0000</pubDate>
      <guid>http://localhost:1313/python/ws_requests_and_beautifulsoup/</guid>
      <description>Import Modules import requests from bs4 import BeautifulSoup # Example adapted from the links below # https://requests.readthedocs.io/en/master/ # https://www.crummy.com/software/BeautifulSoup/bs4/doc/ Request a Web Page html_page = requests.get(&amp;#39;https://www.crummy.com/software/BeautifulSoup/bs4/doc/&amp;#39;, auth=(&amp;#39;user&amp;#39;, &amp;#39;pass&amp;#39;)) Return Page Headers # Return Page Headers html_page.headers[&amp;#39;content-type&amp;#39;] &#39;text/html; charset=UTF-8&#39;&#xD;Return Page Status Code # Return Page Status Code html_page.status_code 200&#xD;Create a Beautiful Soup Object with HTML text # Create a Beautiful Soup Object with HTML text soup = BeautifulSoup(html_page.text, &amp;#39;html.</description>
    </item>
    <item>
      <title>Python os.walk()</title>
      <link>http://localhost:1313/python/oswalk/</link>
      <pubDate>Thu, 28 Jan 2021 14:50:18 +0000</pubDate>
      <guid>http://localhost:1313/python/oswalk/</guid>
      <description> Import Modules # Import Module import os Set Path # Set Path path = &amp;#39;../../content/&amp;#39; Find All Markdown Files In All Content Folders # Find all markdown filesin all content folders all_md_files = [os.path.join(root, name) for root, dirs, files in os.walk(path) for name in files if name.endswith((&amp;#34;.md&amp;#34;))] all_md_files [&#39;../../content/archive\\get-started-with-angular-2.md&#39;,&#xD;&#39;../../content/content\\about\\about.md&#39;,&#xD;&#39;../../content/git\\basic_git_commands.md&#39;,&#xD;&#39;../../content/powershell\\PowerShell.md&#39;,&#xD;&#39;../../content/python\\drop_dataframe_columns.md&#39;,&#xD;&#39;../../content/python\\load_csv.md&#39;,&#xD;&#39;../../content/python\\load_json.md&#39;,&#xD;&#39;../../content/python\\ossystem.md&#39;,&#xD;&#39;../../content/python\\oswalk.md&#39;,&#xD;&#39;../../content/python\\resources.md&#39;,&#xD;&#39;../../content/python\\write_dataframe_to_json.md&#39;,&#xD;&#39;../../content/python\\ws_requests_and_beautifulsoup.md&#39;,&#xD;&#39;../../content/test\\data_analysis.md&#39;,&#xD;&#39;../../content/test\\jira_data_analysis.md&#39;,&#xD;&#39;../../content/test\\reddit_wallstreetbets.md&#39;,&#xD;&#39;../../content/vscode\\inserting_date_time.md&#39;,&#xD;&#39;../../content/vscode\\vscode_python_issues.md&#39;,&#xD;&#39;../../content/vscode\\vscode_shortcuts.md&#39;]&#xD;</description>
    </item>
    <item>
      <title>Load a JSON file</title>
      <link>http://localhost:1313/python/load_json/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 -0800</pubDate>
      <guid>http://localhost:1313/python/load_json/</guid>
      <description>import pandas as pd # Set JSON filepath json_filepath = &amp;#34;data/new_json.json&amp;#34; # Read JSON File df = pd.read_json(json_filepath, orient=&amp;#39;split&amp;#39;) df name&#xD;mfr&#xD;type&#xD;calories&#xD;protein&#xD;fat&#xD;sodium&#xD;fiber&#xD;carbo&#xD;sugars&#xD;potass&#xD;vitamins&#xD;shelf&#xD;weight&#xD;cups&#xD;rating&#xD;0&#xD;100% Bran&#xD;N&#xD;C&#xD;70&#xD;4&#xD;1&#xD;130&#xD;10.0&#xD;5.0&#xD;6&#xD;280&#xD;25&#xD;3&#xD;1.0&#xD;0.33&#xD;68.402973&#xD;1&#xD;100% Natural Bran&#xD;Q&#xD;C&#xD;120&#xD;3&#xD;5&#xD;15&#xD;2.0&#xD;8.0&#xD;8&#xD;135&#xD;0&#xD;3&#xD;1.</description>
    </item>
    <item>
      <title>Load a CSV File</title>
      <link>http://localhost:1313/python/load_csv/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 -0700</pubDate>
      <guid>http://localhost:1313/python/load_csv/</guid>
      <description>Data Source Import Pandas # Import Pandas import pandas as pd Read CSV file #Load CSV file into a dataframe with Pandas df = pd.read_csv(&amp;#39;data/cereal.csv&amp;#39;) #Output Dataframe df name&#xD;mfr&#xD;type&#xD;calories&#xD;protein&#xD;fat&#xD;sodium&#xD;fiber&#xD;carbo&#xD;sugars&#xD;potass&#xD;vitamins&#xD;shelf&#xD;weight&#xD;cups&#xD;rating&#xD;0&#xD;100% Bran&#xD;N&#xD;C&#xD;70&#xD;4&#xD;1&#xD;130&#xD;10.0&#xD;5.0&#xD;6&#xD;280&#xD;25&#xD;3&#xD;1.0&#xD;0.33&#xD;68.402973&#xD;1&#xD;100% Natural Bran&#xD;Q&#xD;C&#xD;120&#xD;3&#xD;5&#xD;15&#xD;2.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/python/image_to_passport/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/image_to_passport/</guid>
      <description>import cv2 from PIL import Image # Load the image image_path = &amp;#39;data/amrit_full.jpg&amp;#39; image = cv2.imread(image_path) # Define the size for the passport photo (e.g., 2x2 inches at 300 DPI) passport_width = int(35 * 11.81) # 35mm to pixels passport_height = int(45 * 11.81) # 45mm to pixels # Resize the image resized_image = cv2.resize(image, (passport_width, passport_height)) # Save the resized image cv2.imwrite(&amp;#39;data/amrit_passport.jpg&amp;#39;, resized_image) # Optional: Convert to RGB and save using Pillow for better quality passport_image = Image.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/python/investment_analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/investment_analysis/</guid>
      <description>import yfinance as yf import pandas as pd import numpy as np import matplotlib.pyplot as plt # Download data from Yahoo Finance etf = &amp;#34;VUSA.L&amp;#34; # Replace with the relevant ticker for your ETF data = yf.download(etf, start=&amp;#34;1990-01-01&amp;#34;, end=&amp;#34;2024-01-01&amp;#34;) # Plot the closing price history plt.figure(figsize=(10,6)) plt.plot(data[&amp;#39;Close&amp;#39;], label=f&amp;#39;{etf} Closing Price&amp;#39;) # Annotate the starting and ending prices start_price = data[&amp;#39;Close&amp;#39;].iloc[0] end_price = data[&amp;#39;Close&amp;#39;].iloc[-1] start_date = data.index[0].strftime(&amp;#39;%Y-%m-%d&amp;#39;) end_date = data.index[-1].strftime(&amp;#39;%Y-%m-%d&amp;#39;) # Add text annotations on the plot for start and end prices plt.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/python/moving_average_analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/moving_average_analysis/</guid>
      <description># Import the required libraries import yfinance as yf import pandas as pd import numpy as np import matplotlib.pyplot as plt # Step 1: Define the stock and download the data # You can change &amp;#39;AAPL&amp;#39; to any other stock ticker symbol stock_ticker = &amp;#39;AAPL&amp;#39; start_date = &amp;#39;2020-01-01&amp;#39; end_date = &amp;#39;2023-01-01&amp;#39; # Download stock data from Yahoo Finance stock_data = yf.download(stock_ticker, start=start_date, end=end_date) [*********************100%***********************] 1 of 1 completed&#xD;# Display the first few rows of the data to ensure it&amp;#39;s been downloaded correctly print(stock_data.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/python/stock_market_analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/stock_market_analysis/</guid>
      <description># Import # In case of a an &amp;#39;No module named&amp;#39; error, install dash, pandas etc # pip install dash import dash import seaborn as sns import matplotlib.pyplot as plt from dash import dcc, html import plotly.express as px import plotly.graph_objs as go import pandas as pd import yfinance as yf # Fetch data #S&amp;amp;P 500 - ^GSPC #S&amp;amp;P 500 Vanguard - VOO #S&amp;amp;P 500 Black Rock - BSPIX #Vanguard Russel Index ETF - VTWO #FTSE 100 - ^FTSE #FTSE 200 - ^FTMC # You can define the various tickers - ticker_symbol = &amp;#39;^GSPC&amp;#39; tickers = [&amp;#39;^GSPC&amp;#39;, &amp;#39;VOO&amp;#39;, &amp;#39;BSPIX&amp;#39;, &amp;#39;VTWO&amp;#39;, &amp;#39;^FTSE&amp;#39;, &amp;#39;^FTMC&amp;#39;] df = yf.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/python/untitled/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python/untitled/</guid>
      <description>## Arrays and Scalars </description>
    </item>
  </channel>
</rss>
