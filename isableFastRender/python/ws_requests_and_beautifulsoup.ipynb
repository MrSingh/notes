{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "---\n",
    "title: \"Requests and Beautiful Soup\"\n",
    "Description: \"Requesting a web page as an object and then usining Beautiful Soup to access various elemets of that object.\"\n",
    "date: 2021-01-29T14:50:18Z\n",
    "draft: false\n",
    "---\n",
    "\n",
    "***\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Example adapted from the links below\n",
    "# https://requests.readthedocs.io/en/master/\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "source": [
    "## Request a Web Page"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_page = requests.get('https://www.crummy.com/software/BeautifulSoup/bs4/doc/', auth=('user', 'pass'))"
   ]
  },
  {
   "source": [
    "## Return Page Headers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'text/html; charset=UTF-8'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Return Page Headers\n",
    "html_page.headers['content-type']"
   ]
  },
  {
   "source": [
    "## Return Page Status Code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Return Page Status Code\n",
    "html_page.status_code"
   ]
  },
  {
   "source": [
    "## Create a Beautiful Soup Object with HTML text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup Object with HTML text\n",
    "soup = BeautifulSoup(html_page.text, 'html.parser')"
   ]
  },
  {
   "source": [
    "## Prettify HTML Text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify HTML Text\n",
    "# print(soup.prettify()) # Uncomment this line to run this cell"
   ]
  },
  {
   "source": [
    "## Return Page Title"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<title>Beautiful Soup Documentation â€” Beautiful Soup 4.9.0 documentation</title>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Return Page Title\n",
    "soup.title"
   ]
  },
  {
   "source": [
    "## Extract all Links"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "genindex.html\n#\n\n#beautiful-soup-documentation\nhttp://www.crummy.com/software/BeautifulSoup/\nhttp://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\n#porting-code-to-bs4\nhttps://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/\nhttp://kondou.com/BS4/\nhttps://www.crummy.com/software/BeautifulSoup/bs4/doc.ko/\nhttps://www.crummy.com/software/BeautifulSoup/bs4/doc.ptbr\nhttps://www.crummy.com/software/BeautifulSoup/bs4/doc.ru/\n#getting-help\nhttps://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\n#diagnose\n#quick-start\n#installing-beautiful-soup\nhttp://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\nhttp://www.crummy.com/software/BeautifulSoup/download/4.x/\n#problems-after-installation\n#installing-a-parser\nhttp://lxml.de/\nhttp://code.google.com/p/html5lib/\n#differences-between-parsers\n#making-the-soup\n#id17\n#kinds-of-objects\n#tag\n#navigating-the-tree\n#searching-the-tree\n#name\n#attributes\n#multi-valued-attributes\n#navigablestring\n#navigating-the-tree\n#searching-the-tree\n#replace-with\n#navigating-the-tree\n#searching-the-tree\n#beautifulsoup\n#tag\n#navigating-the-tree\n#searching-the-tree\n#modifying-the-tree\n#tag\n#comments-and-other-special-strings\n#navigating-the-tree\n#going-down\n#navigating-using-tag-names\n#searching-the-tree\n#contents-and-children\n#descendants\n#string\n#strings-and-stripped-strings\n#going-up\n#parent\n#parents\n#going-sideways\n#next-sibling-and-previous-sibling\n#next-siblings-and-previous-siblings\n#going-back-and-forth\n#next-element-and-previous-element\n#next-elements-and-previous-elements\n#searching-the-tree\n#kinds-of-filters\n#a-string\n#a-regular-expression\n#a-list\n#true\n#a-function\n#find-all\n#id12\n#attrs\n#recursive\n#id13\n#limit\n#kwargs\n#kinds-of-filters\n#the-name-argument\n#kinds-of-filters\n#a-string\n#a-regular-expression\n#a-list\n#a-function\n#the-value-true\n#the-keyword-arguments\n#a-string\n#a-regular-expression\n#a-list\n#a-function\n#the-value-true\n#searching-by-css-class\n#multivalue\n#the-string-argument\n#a-string\n#a-regular-expression\n#a-list\n#a-function\n#the-value-true\n#the-limit-argument\n#the-recursive-argument\n#calling-a-tag-is-like-calling-find-all\n#find\n#id12\n#attrs\n#recursive\n#id13\n#kwargs\n#navigating-using-tag-names\n#find-parents-and-find-parent\n#id12\n#attrs\n#id13\n#limit\n#kwargs\n#id12\n#attrs\n#id13\n#kwargs\n#parent\n#parents\n#find-next-siblings-and-find-next-sibling\n#id12\n#attrs\n#id13\n#limit\n#kwargs\n#id12\n#attrs\n#id13\n#kwargs\n#sibling-generators\n#find-previous-siblings-and-find-previous-sibling\n#id12\n#attrs\n#id13\n#limit\n#kwargs\n#id12\n#attrs\n#id13\n#kwargs\n#sibling-generators\n#find-all-next-and-find-next\n#id12\n#attrs\n#id13\n#limit\n#kwargs\n#id12\n#attrs\n#id13\n#kwargs\n#element-generators\n#find-all-previous-and-find-previous\n#id12\n#attrs\n#id13\n#limit\n#kwargs\n#id12\n#attrs\n#id13\n#kwargs\n#element-generators\n#css-selectors\nhttps://facelessuser.github.io/soupsieve/\nhttps://facelessuser.github.io/soupsieve/\n#modifying-the-tree\n#changing-tag-names-and-attributes\n#attributes\n#modifying-string\n#append\n#extend\n#navigablestring-and-new-tag\n#insert\n#insert-before-and-insert-after\n#clear\n#extract\n#decompose\n#replace-with\n#wrap\n#unwrap\n#smooth\n#output\n#pretty-printing\n#non-pretty-printing\n#encodings\n#output-formatters\n#get-text\n#string-generators\n#specifying-the-parser-to-use\n#installing-a-parser\n#differences-between-parsers\n#encodings\n#unicode-dammit\n#output-encoding\n#unicode-dammit\n#smart-quotes\n#inconsistent-encodings\n#line-numbers\n#comparing-objects-for-equality\n#copying-beautiful-soup-objects\n#advanced-parser-customization\n#parsing-only-part-of-a-document\n#soupstrainer\n#searching-the-tree\n#id12\n#attrs\n#id13\n#kwargs\n#searching-the-tree\n#customizing-multi-valued-attributes\n#handling-duplicate-attributes\n#instantiating-custom-subclasses\n#troubleshooting\n#diagnose\n#errors-when-parsing-a-document\n#installing-a-parser\n#parser-installation\n#parser-installation\n#version-mismatch-problems\n#parsing-xml\n#parser-installation\n#other-parser-problems\n#differences-between-parsers\nhttp://www.w3.org/TR/html5/syntax.html#syntax\n#parsing-xml\n#miscellaneous\nhttp://wiki.python.org/moin/PrintFails\n#improving-performance\nhttp://lxml.de/\n#parser-installation\nhttp://pypi.python.org/pypi/cchardet/\n#parsing-only-part-of-a-document\n#translating-this-documentation\n#id18\nhttp://www.crummy.com/software/BeautifulSoup/bs3/download/3.x/BeautifulSoup-3.2.0.tar.gz\nhttp://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\n#porting-code-to-bs4\nhttp://www.python.org/dev/peps/pep-0008/\n#you-need-a-parser\n#installing-a-parser\n#method-names\n#generators\n#string-generators\n#xml\n#entities\n#unicode-dammit\n#output-formatters\n#id19\n#string\n#multi-valued-attributes\n#id13\n#id12\n#string\n#id13\n#\n#\n#getting-help\n#quick-start\n#installing-beautiful-soup\n#problems-after-installation\n#installing-a-parser\n#making-the-soup\n#kinds-of-objects\n#tag\n#name\n#attributes\n#multi-valued-attributes\n#navigablestring\n#beautifulsoup\n#comments-and-other-special-strings\n#navigating-the-tree\n#going-down\n#navigating-using-tag-names\n#contents-and-children\n#descendants\n#string\n#strings-and-stripped-strings\n#going-up\n#parent\n#parents\n#going-sideways\n#next-sibling-and-previous-sibling\n#next-siblings-and-previous-siblings\n#going-back-and-forth\n#next-element-and-previous-element\n#next-elements-and-previous-elements\n#searching-the-tree\n#kinds-of-filters\n#a-string\n#a-regular-expression\n#a-list\n#true\n#a-function\n#find-all\n#the-name-argument\n#the-keyword-arguments\n#searching-by-css-class\n#the-string-argument\n#the-limit-argument\n#the-recursive-argument\n#calling-a-tag-is-like-calling-find-all\n#find\n#find-parents-and-find-parent\n#find-next-siblings-and-find-next-sibling\n#find-previous-siblings-and-find-previous-sibling\n#find-all-next-and-find-next\n#find-all-previous-and-find-previous\n#css-selectors\n#modifying-the-tree\n#changing-tag-names-and-attributes\n#modifying-string\n#append\n#extend\n#navigablestring-and-new-tag\n#insert\n#insert-before-and-insert-after\n#clear\n#extract\n#decompose\n#replace-with\n#wrap\n#unwrap\n#smooth\n#output\n#pretty-printing\n#non-pretty-printing\n#output-formatters\n#get-text\n#specifying-the-parser-to-use\n#differences-between-parsers\n#encodings\n#output-encoding\n#unicode-dammit\n#smart-quotes\n#inconsistent-encodings\n#line-numbers\n#comparing-objects-for-equality\n#copying-beautiful-soup-objects\n#advanced-parser-customization\n#parsing-only-part-of-a-document\n#soupstrainer\n#customizing-multi-valued-attributes\n#handling-duplicate-attributes\n#instantiating-custom-subclasses\n#troubleshooting\n#diagnose\n#errors-when-parsing-a-document\n#version-mismatch-problems\n#parsing-xml\n#other-parser-problems\n#miscellaneous\n#improving-performance\n#translating-this-documentation\n#id18\n#porting-code-to-bs4\n#you-need-a-parser\n#method-names\n#generators\n#xml\n#entities\n#id19\n_sources/index.rst.txt\ngenindex.html\n#\n\nhttps://www.sphinx-doc.org/\n"
     ]
    }
   ],
   "source": [
    "# Extract all links\n",
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "source": [
    "## Extract all Text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Text\n",
    "# print(soup.get_text()) # Uncomment this line to run this cell"
   ]
  }
 ]
}